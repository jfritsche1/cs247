{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinBERT Example Notebook\n",
    "\n",
    "This notebooks shows how to train and use the FinBERT pre-trained language model for financial sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:36.919958Z",
     "start_time": "2019-10-29T16:08:35.931898Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import argparse\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import *\n",
    "\n",
    "from finbert.finbert import *\n",
    "import finbert.utils as tools\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:37.673551Z",
     "start_time": "2019-10-29T16:08:37.655002Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting path variables:\n",
    "1. `lm_path`: the path for the pre-trained language model (If vanilla Bert is used then no need to set this one).\n",
    "2. `cl_path`: the path where the classification model is saved.\n",
    "3. `cl_data_path`: the path of the directory that contains the data files of `train.csv`, `validation.csv`, `test.csv`.\n",
    "---\n",
    "\n",
    "In the initialization of `bertmodel`, we can either use the original pre-trained weights from Google by giving `bm = 'bert-base-uncased`, or our further pre-trained language model by `bm = lm_path`\n",
    "\n",
    "\n",
    "---\n",
    "All of the configurations with the model is controlled with the `config` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:39.655461Z",
     "start_time": "2019-10-29T16:08:39.636765Z"
    }
   },
   "outputs": [],
   "source": [
    "lm_path = project_dir/'models'/'language_model'/'finbertTRC2'\n",
    "cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n",
    "cl_data_path = project_dir/'data'/'sentiment_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Configuring training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the explanations of the training parameters in the class docsctrings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:44.034783Z",
     "start_time": "2019-10-29T16:08:41.088558Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:03:31 - INFO - pytorch_pretrained_bert.modeling -   loading archive file c:\\Users\\JohnEE\\Documents\\repos\\tests\\test_finbert\\finBERT\\models\\language_model\\finbertTRC2 from cache at c:\\Users\\JohnEE\\Documents\\repos\\tests\\test_finbert\\finBERT\\models\\language_model\\finbertTRC2\n",
      "06/02/2021 10:03:31 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "06/02/2021 10:03:32 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "06/02/2021 10:03:32 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "# Clean the cl_path\n",
    "try:\n",
    "    shutil.rmtree(cl_path) \n",
    "except:\n",
    "    pass\n",
    "\n",
    "bertmodel = BertForSequenceClassification.from_pretrained(lm_path,cache_dir=None, num_labels=3)\n",
    "\n",
    "\n",
    "config = Config(   data_dir=cl_data_path,\n",
    "                   bert_model=bertmodel,\n",
    "                   num_train_epochs=4,\n",
    "                   model_dir=cl_path,\n",
    "                   max_seq_length = 64,\n",
    "                   train_batch_size = 32,\n",
    "                   learning_rate = 2e-5,\n",
    "                   output_mode='classification',\n",
    "                   warm_up_proportion=0.2,\n",
    "                   local_rank=-1,\n",
    "                   discriminate=True,\n",
    "                   gradual_unfreeze=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`finbert` is our main class that encapsulates all the functionality. The list of class labels should be given in the prepare_model method call with label_list parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:44.057356Z",
     "start_time": "2019-10-29T16:08:44.036481Z"
    }
   },
   "outputs": [],
   "source": [
    "finbert = FinBert(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:45.564182Z",
     "start_time": "2019-10-29T16:08:44.879593Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:03:33 - INFO - finbert.finbert -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "06/02/2021 10:03:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\JohnEE\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "finbert.prepare_model(label_list=['positive','negative','neutral'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:47.013944Z",
     "start_time": "2019-10-29T16:08:46.935123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the training examples\n",
    "train_data = finbert.get_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:08:50.638327Z",
     "start_time": "2019-10-29T16:08:47.789042Z"
    }
   },
   "outputs": [],
   "source": [
    "model = finbert.create_the_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Fine-tune only a subset of the model\n",
    "The variable `freeze` determines the last layer (out of 12) to be freezed. You can skip this part if you want to fine-tune the whole model.\n",
    "\n",
    "<span style=\"color:red\">Important: </span>\n",
    "Execute this step if you want a shorter training time in the expense of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for fine-tuning a subset of the model.\n",
    "\n",
    "freeze = 11\n",
    "\n",
    "for param in model.bert.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for i in range(freeze):\n",
    "    for param in model.bert.encoder.layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:12:50.884001Z",
     "start_time": "2019-10-29T16:08:53.185242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:03:42 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:03:42 - INFO - finbert.utils -   guid: train-1\n",
      "06/02/2021 10:03:42 - INFO - finbert.utils -   tokens: [CLS] nl ##s ##n via ##c disney media giant miss out ##of ##hom ##e rating boost [SEP]\n",
      "06/02/2021 10:03:42 - INFO - finbert.utils -   input_ids: 101 17953 2015 2078 3081 2278 6373 2865 5016 3335 2041 11253 23393 2063 5790 12992 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:03:42 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:03:42 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:03:42 - INFO - finbert.utils -   label: positive (id = 0)\n",
      "06/02/2021 10:03:42 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/02/2021 10:03:42 - INFO - finbert.finbert -     Num examples = 936\n",
      "06/02/2021 10:03:42 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/02/2021 10:03:42 - INFO - finbert.finbert -     Num steps = 12\n",
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=30.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40bd3fad77e74bfab7b307480108e6e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\JohnEE\\anaconda3\\envs\\finbert_testing\\lib\\site-packages\\pytorch_pretrained_bert\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1005.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   guid: validation-1\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   tokens: [CLS] alert two ##year focused assessment modelling [SEP]\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   input_ids: 101 9499 2048 29100 4208 7667 19518 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:05:38 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "06/02/2021 10:05:38 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/02/2021 10:05:38 - INFO - finbert.finbert -     Num examples = 104\n",
      "06/02/2021 10:05:38 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/02/2021 10:05:38 - INFO - finbert.finbert -     Num steps = 12\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=0.0, max=4.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00a588df8b63455ca9df178eb0854575"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Validation losses: [1.0895976126194]\n",
      "No best model found\n",
      "Epoch:  25%|██▌       | 1/4 [02:05<06:15, 125.17s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=30.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eba2c3b90e364100bf915b7f3951f8f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:08:27 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:08:27 - INFO - finbert.utils -   guid: validation-1\n",
      "06/02/2021 10:08:27 - INFO - finbert.utils -   tokens: [CLS] alert two ##year focused assessment modelling [SEP]\n",
      "06/02/2021 10:08:27 - INFO - finbert.utils -   input_ids: 101 9499 2048 29100 4208 7667 19518 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:08:27 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:08:27 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:08:27 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "06/02/2021 10:08:27 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/02/2021 10:08:27 - INFO - finbert.finbert -     Num examples = 104\n",
      "06/02/2021 10:08:27 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/02/2021 10:08:27 - INFO - finbert.finbert -     Num steps = 12\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=0.0, max=4.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6796d6b080c34e0a86a86c247d406c39"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Validation losses: [1.0895976126194, 0.9884044826030731]\n",
      "Epoch:  50%|█████     | 2/4 [04:54<04:36, 138.40s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=30.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22a4ac96aa72488aabd9398813df5008"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:12:03 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:12:03 - INFO - finbert.utils -   guid: validation-1\n",
      "06/02/2021 10:12:03 - INFO - finbert.utils -   tokens: [CLS] alert two ##year focused assessment modelling [SEP]\n",
      "06/02/2021 10:12:03 - INFO - finbert.utils -   input_ids: 101 9499 2048 29100 4208 7667 19518 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:12:03 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:12:03 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:12:03 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "06/02/2021 10:12:03 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/02/2021 10:12:03 - INFO - finbert.finbert -     Num examples = 104\n",
      "06/02/2021 10:12:03 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/02/2021 10:12:03 - INFO - finbert.finbert -     Num steps = 12\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=0.0, max=4.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26fed9f9633147d6b3ebf7104b57fd2b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Validation losses: [1.0895976126194, 0.9884044826030731, 0.8358816206455231]\n",
      "Epoch:  75%|███████▌  | 3/4 [08:29<02:41, 161.51s/it]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=30.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ac19653b10d4e208d9c761d2794f7fc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:16:05 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "06/02/2021 10:16:13 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "06/02/2021 10:16:16 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   guid: validation-1\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   tokens: [CLS] alert two ##year focused assessment modelling [SEP]\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   input_ids: 101 9499 2048 29100 4208 7667 19518 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:16:17 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "06/02/2021 10:16:17 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/02/2021 10:16:17 - INFO - finbert.finbert -     Num examples = 104\n",
      "06/02/2021 10:16:17 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/02/2021 10:16:17 - INFO - finbert.finbert -     Num steps = 12\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=0.0, max=4.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "065a13288b8c49f28588b1f0c78c1002"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Validation losses: [1.0895976126194, 0.9884044826030731, 0.8358816206455231, 0.741437628865242]\n",
      "Epoch: 100%|██████████| 4/4 [12:43<00:00, 190.99s/it]\n"
     ]
    }
   ],
   "source": [
    "trained_model = finbert.train(train_examples = train_data, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "`bert.evaluate` outputs the DataFrame, where true labels and logit values for each example is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:12:50.906088Z",
     "start_time": "2019-10-29T16:12:50.885757Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = finbert.get_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:01.003479Z",
     "start_time": "2019-10-29T16:12:53.092063Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:20:21 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:20:21 - INFO - finbert.utils -   guid: test-1\n",
      "06/02/2021 10:20:21 - INFO - finbert.utils -   tokens: [CLS] morgan stanley raises al ##gon ##quin power utilities a ##q ##n price target [SEP]\n",
      "06/02/2021 10:20:21 - INFO - finbert.utils -   input_ids: 101 5253 6156 13275 2632 7446 12519 2373 16548 1037 4160 2078 3976 4539 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:20:21 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:20:21 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:20:21 - INFO - finbert.utils -   label: neutral (id = 2)\n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -   ***** Loading data *****\n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -     Num examples = 260\n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -     Batch size = 32\n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -     Num steps = 32\n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -   ***** Running evaluation ***** \n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -     Num examples = 260\n",
      "06/02/2021 10:20:21 - INFO - finbert.finbert -     Batch size = 32\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=9.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72fa95c4560c407e9b785d561b3d631e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = finbert.evaluate(examples=test_data, model=trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:03.215753Z",
     "start_time": "2019-10-29T16:13:03.196333Z"
    }
   },
   "outputs": [],
   "source": [
    "def report(df, cols=['label','prediction','logits']):\n",
    "    #print('Validation loss:{0:.2f}'.format(metrics['best_validation_loss']))\n",
    "    cs = CrossEntropyLoss(weight=finbert.class_weights)\n",
    "    loss = cs(torch.tensor(list(df[cols[2]])),torch.tensor(list(df[cols[0]])))\n",
    "    print(\"Loss:{0:.2f}\".format(loss))\n",
    "    print(\"Accuracy:{0:.2f}\".format((df[cols[0]] == df[cols[1]]).sum() / df.shape[0]) )\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(df[cols[0]], df[cols[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:04.104588Z",
     "start_time": "2019-10-29T16:13:04.083586Z"
    }
   },
   "outputs": [],
   "source": [
    "results['prediction'] = results.predictions.apply(lambda x: np.argmax(x,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:04.774938Z",
     "start_time": "2019-10-29T16:13:04.743757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss:0.84\nAccuracy:0.59\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.75      0.48      0.59       120\n           1       0.49      0.69      0.57        62\n           2       0.55      0.67      0.60        78\n\n    accuracy                           0.59       260\n   macro avg       0.60      0.61      0.59       260\nweighted avg       0.63      0.59      0.59       260\n\n"
     ]
    }
   ],
   "source": [
    "report(results,cols=['labels','prediction','predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `predict` function, given a piece of text, we split it into a list of sentences and then predict sentiment for each sentence. The output is written into a dataframe. Predictions are represented in three different columns: \n",
    "\n",
    "1) `logit`: probabilities for each class\n",
    "\n",
    "2) `prediction`: predicted label\n",
    "\n",
    "3) `sentiment_score`: sentiment score calculated as: probability of positive - probability of negative\n",
    "\n",
    "Below we analyze a paragraph taken out of [this](https://www.economist.com/finance-and-economics/2019/01/03/a-profit-warning-from-apple-jolts-markets) article from The Economist. For comparison purposes, we also put the sentiments predicted with TextBlob.\n",
    "> Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. The news rapidly infected financial markets. Apple’s share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened. The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. Yields on government bonds fell as investors fled to the traditional haven in a market storm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:13.211996Z",
     "start_time": "2019-10-29T16:13:13.195163Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Later that day Apple said it was revising down its earnings expectations in \\\n",
    "the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China. \\\n",
    "The news rapidly infected financial markets. Apple’s share price fell by around 7% in after-hours \\\n",
    "trading and the decline was extended to more than 10% when the market opened. The dollar fell \\\n",
    "by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering \\\n",
    "some ground. Asian stockmarkets closed down on January 3rd and European ones opened lower. \\\n",
    "Yields on government bonds fell as investors fled to the traditional haven in a market storm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:16.846826Z",
     "start_time": "2019-10-29T16:13:13.854602Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:21:11 - INFO - pytorch_pretrained_bert.modeling -   loading archive file c:\\Users\\JohnEE\\Documents\\repos\\tests\\test_finbert\\finBERT\\models\\classifier_model\\finbert-sentiment from cache at c:\\Users\\JohnEE\\Documents\\repos\\tests\\test_finbert\\finBERT\\models\\classifier_model\\finbert-sentiment\n",
      "06/02/2021 10:21:11 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_path = project_dir/'models'/'classifier_model'/'finbert-sentiment'\n",
    "model = BertForSequenceClassification.from_pretrained(cl_path, cache_dir=None, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:17.464289Z",
     "start_time": "2019-10-29T16:13:16.848874Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:21:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\JohnEE\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   guid: 0\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   tokens: [CLS] later that day apple said it was rev ##ising down its earnings expectations in the fourth quarter of 2018 , largely because of lower sales and signs of economic weakness in china . [SEP]\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   input_ids: 101 2101 2008 2154 6207 2056 2009 2001 7065 9355 2091 2049 16565 10908 1999 1996 2959 4284 1997 2760 1010 4321 2138 1997 2896 4341 1998 5751 1997 3171 11251 1999 2859 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:21:15 - INFO - finbert.utils -   label: None (id = 9090)\n"
     ]
    }
   ],
   "source": [
    "result = predict(text,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:18.440875Z",
     "start_time": "2019-10-29T16:13:18.368559Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                                                                                                          sentence  \\\n",
       "0  Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China.   \n",
       "1  The news rapidly infected financial markets.                                                                                                                                      \n",
       "2  Apple’s share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened.                                                \n",
       "3  The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground.                                                     \n",
       "4  Asian stockmarkets closed down on January 3rd and European ones opened lower.                                                                                                     \n",
       "5  Yields on government bonds fell as investors fled to the traditional haven in a market storm.                                                                                     \n",
       "\n",
       "                                  logit prediction  sentiment_score  \\\n",
       "0  [0.25908384, 0.46594453, 0.2749717]   negative  -0.206861          \n",
       "1  [0.24254285, 0.39610776, 0.36134937]  negative  -0.153565          \n",
       "2  [0.22312458, 0.50865084, 0.26822457]  negative  -0.285526          \n",
       "3  [0.32277292, 0.47576383, 0.20146321]  negative  -0.152991          \n",
       "4  [0.21313731, 0.66439164, 0.12247105]  negative  -0.451254          \n",
       "5  [0.30958334, 0.43190542, 0.25851128]  negative  -0.122322          \n",
       "\n",
       "   textblob_prediction  \n",
       "0  0.051746             \n",
       "1  0.000000             \n",
       "2  0.500000             \n",
       "3  0.000000             \n",
       "4 -0.051111             \n",
       "5  0.000000             "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>logit</th>\n      <th>prediction</th>\n      <th>sentiment_score</th>\n      <th>textblob_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Later that day Apple said it was revising down its earnings expectations in the fourth quarter of 2018, largely because of lower sales and signs of economic weakness in China.</td>\n      <td>[0.25908384, 0.46594453, 0.2749717]</td>\n      <td>negative</td>\n      <td>-0.206861</td>\n      <td>0.051746</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The news rapidly infected financial markets.</td>\n      <td>[0.24254285, 0.39610776, 0.36134937]</td>\n      <td>negative</td>\n      <td>-0.153565</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Apple’s share price fell by around 7% in after-hours trading and the decline was extended to more than 10% when the market opened.</td>\n      <td>[0.22312458, 0.50865084, 0.26822457]</td>\n      <td>negative</td>\n      <td>-0.285526</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The dollar fell by 3.7% against the yen in a matter of minutes after the announcement, before rapidly recovering some ground.</td>\n      <td>[0.32277292, 0.47576383, 0.20146321]</td>\n      <td>negative</td>\n      <td>-0.152991</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Asian stockmarkets closed down on January 3rd and European ones opened lower.</td>\n      <td>[0.21313731, 0.66439164, 0.12247105]</td>\n      <td>negative</td>\n      <td>-0.451254</td>\n      <td>-0.051111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Yields on government bonds fell as investors fled to the traditional haven in a market storm.</td>\n      <td>[0.30958334, 0.43190542, 0.25851128]</td>\n      <td>negative</td>\n      <td>-0.122322</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "result['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:21.930772Z",
     "start_time": "2019-10-29T16:13:21.913129Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average sentiment is -0.23.\n"
     ]
    }
   ],
   "source": [
    "print(f'Average sentiment is %.2f.' % (result.sentiment_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:23.235048Z",
     "start_time": "2019-10-29T16:13:23.220155Z"
    }
   },
   "outputs": [],
   "source": [
    "text2 = \"Shares in the spin-off of South African e-commerce group Naspers surged more than 25% \\\n",
    "in the first minutes of their market debut in Amsterdam on Wednesday. Bob van Dijk, CEO of \\\n",
    "Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the \\\n",
    "Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019. REUTERS/Piroschka van de Wouw \\\n",
    "Prosus comprises Naspers’ global empire of consumer internet assets, with the jewel in the crown a \\\n",
    "31% stake in Chinese tech titan Tencent. There is 'way more demand than is even available, so that’s \\\n",
    "good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg. 'It’s going to be an interesting \\\n",
    "hour of trade after opening this morning.' Euronext had given an indicative price of 58.70 euros \\\n",
    "per share for Prosus, implying a market value of 95.3 billion euros ($105 billion). The shares \\\n",
    "jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:25.282742Z",
     "start_time": "2019-10-29T16:13:24.059548Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "06/02/2021 10:21:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\JohnEE\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   *** Example ***\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   guid: 0\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   tokens: [CLS] shares in the spin - off of south african e - commerce group nas ##pers surged more than 25 % in the first minutes of their market debut in amsterdam on wednesday . [SEP]\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   input_ids: 101 6661 1999 1996 6714 1011 2125 1997 2148 3060 1041 1011 6236 2177 17235 7347 18852 2062 2084 2423 1003 1999 1996 2034 2781 1997 2037 3006 2834 1999 7598 2006 9317 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "06/02/2021 10:21:29 - INFO - finbert.utils -   label: None (id = 9090)\n"
     ]
    }
   ],
   "source": [
    "result2 = predict(text2,model)\n",
    "blob = TextBlob(text2)\n",
    "result2['textblob_prediction'] = [sentence.sentiment.polarity for sentence in blob.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:26.333524Z",
     "start_time": "2019-10-29T16:13:26.308562Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                                                                                                                    sentence  \\\n",
       "0  Shares in the spin-off of South African e-commerce group Naspers surged more than 25% in the first minutes of their market debut in Amsterdam on Wednesday.                                 \n",
       "1  Bob van Dijk, CEO of Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019.   \n",
       "2  REUTERS/Piroschka van de Wouw Prosus comprises Naspers’ global empire of consumer internet assets, with the jewel in the crown a 31% stake in Chinese tech titan Tencent.                   \n",
       "3  There is 'way more demand than is even available, so that’s good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg.                                                                 \n",
       "4  'It’s going to be an interesting hour of trade after opening this morning.'                                                                                                                 \n",
       "5  Euronext had given an indicative price of 58.70 euros per share for Prosus, implying a market value of 95.3 billion euros ($105 billion).                                                   \n",
       "6  The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.                                                                                                          \n",
       "\n",
       "                                  logit prediction  sentiment_score  \\\n",
       "0  [0.386195, 0.36844802, 0.24535695]    positive   0.017747          \n",
       "1  [0.14924668, 0.10255987, 0.74819344]  neutral    0.046687          \n",
       "2  [0.48308653, 0.24628338, 0.27063006]  positive   0.236803          \n",
       "3  [0.39126176, 0.410624, 0.19811423]    negative  -0.019362          \n",
       "4  [0.48813695, 0.25179604, 0.26006708]  positive   0.236341          \n",
       "5  [0.2675149, 0.31091088, 0.42157418]   neutral   -0.043396          \n",
       "6  [0.28909075, 0.2424854, 0.46842387]   neutral    0.046605          \n",
       "\n",
       "   textblob_prediction  \n",
       "0  0.250000             \n",
       "1  0.000000             \n",
       "2  0.000000             \n",
       "3  0.533333             \n",
       "4  0.500000             \n",
       "5  0.000000             \n",
       "6  0.000000             "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>logit</th>\n      <th>prediction</th>\n      <th>sentiment_score</th>\n      <th>textblob_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Shares in the spin-off of South African e-commerce group Naspers surged more than 25% in the first minutes of their market debut in Amsterdam on Wednesday.</td>\n      <td>[0.386195, 0.36844802, 0.24535695]</td>\n      <td>positive</td>\n      <td>0.017747</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bob van Dijk, CEO of Naspers and Prosus Group poses at Amsterdam's stock exchange, as Prosus begins trading on the Euronext stock exchange in Amsterdam, Netherlands, September 11, 2019.</td>\n      <td>[0.14924668, 0.10255987, 0.74819344]</td>\n      <td>neutral</td>\n      <td>0.046687</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>REUTERS/Piroschka van de Wouw Prosus comprises Naspers’ global empire of consumer internet assets, with the jewel in the crown a 31% stake in Chinese tech titan Tencent.</td>\n      <td>[0.48308653, 0.24628338, 0.27063006]</td>\n      <td>positive</td>\n      <td>0.236803</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There is 'way more demand than is even available, so that’s good,' said the CEO of Euronext Amsterdam, Maurice van Tilburg.</td>\n      <td>[0.39126176, 0.410624, 0.19811423]</td>\n      <td>negative</td>\n      <td>-0.019362</td>\n      <td>0.533333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>'It’s going to be an interesting hour of trade after opening this morning.'</td>\n      <td>[0.48813695, 0.25179604, 0.26006708]</td>\n      <td>positive</td>\n      <td>0.236341</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Euronext had given an indicative price of 58.70 euros per share for Prosus, implying a market value of 95.3 billion euros ($105 billion).</td>\n      <td>[0.2675149, 0.31091088, 0.42157418]</td>\n      <td>neutral</td>\n      <td>-0.043396</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>The shares jumped to 76 euros on opening and were trading at 75 euros at 0719 GMT.</td>\n      <td>[0.28909075, 0.2424854, 0.46842387]</td>\n      <td>neutral</td>\n      <td>0.046605</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T16:13:27.604870Z",
     "start_time": "2019-10-29T16:13:27.589629Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average sentiment is 0.07.\n"
     ]
    }
   ],
   "source": [
    "print(f'Average sentiment is %.2f.' % (result2.sentiment_score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd09610836e297a3665a40693b701b16fa1b88a3b3669900e49d937d53a265ca84d",
   "display_name": "Python 3.7.3 64-bit ('finbert_testing': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}